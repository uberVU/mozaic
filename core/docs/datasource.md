# OVERVIEW

    The datasource is where mozaic manages all incoming/outgoing data. The
    datasource plugins into the backend apis to fetch data for you mozaic app
    or to save data generated by your mozaic app.

    It handles all the "nitty-gritty" [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/AJAX)
    process, as well as data serialization, proper request params and headers
    and offers the application level an abstraction called a `channel`.

    A channel is an evented source of data where the application, specifically
    the widgets, can listen for data changes comming in and also trigger changes
    to the data that will be propagated by mozaic to all other components listening
    in to those channels.

    The way channels are implemented is closely related to the way Backbone works.
    Backbone [Models](http://backbonejs.org/#Model) and [Collections](http://backbonejs.org/#Collection)
    are the ones that fetch data from the server. This information is then exposed
    in a low coupled way through channels identified by their name. Widgets
    declare their interest in certain channels given their names and the handlers
    to be executed when any event gets triggered on that channel.

    Here is an example:

    ````coffeescript
    class SomeWidget extends Widget
        # Widget notifies the Datasource that it wants to listen to events on
        # the `/some_channel` channel.
        subscribed_channels: ['/some_channel']

        get_some_channel: (params) ->
            ###
                Widget registers a callback that will execute whenever there is
                a new event on `/some_channel` event. Below is a struction of
                the `params` object received as parameter
                @param {Object} params
                @param {String} params.type - this is the event received on that channel.
                @param {Object} [params.model] - instance of Backbone.Model passed
                        when the event received is only related to a model
                @param {Object} [params.collection] - instance of Backbone.Collection
                        passed when the event received is related to a collection of models
            ###
            if params.type in ['change', 'reset']
                # re-render the layout with the new data.

    ````

    Note that a channel can represent both a collection of homogenous model instances
    or a single model instance. The datasource api is agnostic of the backing
    datastructure, whether it is a model or a channel. However each type of
    backing datastructure also trigger specific events, which closely map to those
    issued by Backbone.

    See [catalog of backbone built in events](http://backbonejs.org/#Events-catalog)
    to have the complete list of the events Backbone models and collections produce,
    the review [the correspondence with mozaic events](https://github.com/uberVU/mozaic/blob/master/core/widget/backbone_events.coffee)

    You might wander why do we go to all this trouble of building this intricate,
    costly and restraining abstraction. The answer is that this keeps the widgets
    __reusable__. As long as you supply the correct channels to a widget, it can
    function anywhere you inject it and in any context.


# CHANNEL CONFIGURATION

App.DataSourceConfig.channel_types is a dictionary mapping channel names to
channel config options. These options are explained below:

    type: 'relational' or 'api'
    url: where to fetch data from (via Backbone.Collection.fetch)
    collection: the Backbone collection to use for this channel

    refresh: 'periodic', 'backoff' or undefined
        Sets the refreshing policy:
         * periodic -> refresh channel every refresh_interval ms
         * backoff -> like periodic, but also applies an exponential backoff
           when no new items are discovered via refreshing (x2, x4, x8, etc)
    refresh_interval:
        Refresh frequency, in miliseconds (used only when refresh='periodic').
    max_refresh_interval:
        Maximum refresh interval, in miliseconds (used only when
        refresh='backoff'). Defaults to 10 x refresh_interval.
    refresh_type: 'refresh' (default), 'streampoll' or 'scroll'
        What should happen when the channel is refreshed (used only when
        refresh='periodic'):
         * refresh (default) -> the entire channel is refreshed
         * streampoll -> check for new items (see Streampoll section below)
         * scroll -> the channel is scrolled down (makes little sense to
           have this as a periodic refresh, but it works)

    buffer_size: undefined (default) or number (e.g.: 100)
        Used only when refresh_type='streampoll' - the buffer size (if number),
        or no buffer (if undefined).

    scroll_params:
        A (data, params) -> params function that returns the url params needed
        to "scroll" the channel down.

    streampoll_params:
        A (data, params) -> params function that returns the url params needed
        to "streampoll" the channel up (check for new items).
        IMPORTANT - returning null (or anything that evaluates to false)
        will stop the current streampoll event!

*** Streampoll ***

Most channels have items that are sorted by a time attribute (e.g.: published,
since_id, etc.) and their corresponding apicalls support time filtering by
those attributes (e.g.: ?since=1338301000). New items appear in these
datasources in increasing order, you could imagine these channels as "streams".

In those cases, it is possible to configure channels to periodically check
their datasources for new (fresh) items. This check is called a "streampoll"
event/request.

When new items are found via a "streampoll" event, two outcomes are possible:
 1) insert the new items directly in the channel's data (buffer_size=null)
 2) keep the new items in the channel's buffer (buffer_size=100);
    triggering a "/refresh" will cause the buffer to be flushed
    into the channel's data, iff it is NOT full (if it is full, a simple
    refresh will be performed)

WARNING! If you set buffer_size to null and the channel has a lot of new items,
a gap might appear in your data: because each streampoll event only fetches
a single apicall, if the new (fresh) items cannot fit into a single apicall,
then not all new items will be added to the channel data. In order to overcome
this, multiple apicalls would be needed and this was not implemented (nor is
it scheduled).
